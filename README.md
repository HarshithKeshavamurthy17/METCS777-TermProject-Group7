# Wikipedia Clickstream Anomaly Detection System

**Team 7 - MET CS 777 Big Data Analytics**  
Harshith Keshavamurthy ‚Ä¢ Aryaman Jalali ‚Ä¢ Dirgha Jivani

---

## What We Built

We built a complete Big Data pipeline that analyzes Wikipedia clickstream data to find unusual navigation patterns. Think of it like this: millions of people navigate Wikipedia every day, clicking from one article to another. Our system processes all those clicks (tens of GB of data per month) and automatically identifies three types of anomalies:

1. **Traffic Spikes** - When an article suddenly gets WAY more traffic than normal (like when breaking news happens)
2. **Mix-Shifts** - When the sources of traffic to an article change dramatically (e.g., suddenly everyone's coming from Google instead of other Wikipedia pages)
3. **Navigation Edges** - Unusual paths between articles that don't match normal user behavior

We used Apache Spark to handle the massive data volumes and built an interactive dashboard where you can explore all the anomalies we found.

---

## Quick Links

- üöÄ **Want to see it in action?** Jump to [Running the Dashboard](#step-3-launch-the-dashboard)
- üìä **Our Results**: We found 2,346 anomalies across 6 months of data
- üíª **GitHub**: You're already here!

---

## What You Need Before Starting

### Required Software

**1. Python 3.8 or higher**

Check if you have it:
```bash
python3 --version
```

If you see `Python 3.8.x` or higher, you're good! If not, download from [python.org](https://www.python.org/downloads/).

**2. Java 8 or 11** (needed for Spark)

Check if you have it:
```bash
java -version
```

You should see something like `java version "11.0.x"` or `"1.8.0_xxx"`.

**If you don't have Java:**
- **Mac**: `brew install openjdk@11`
- **Ubuntu/Debian**: `sudo apt-get install openjdk-11-jdk`
- **Windows**: Download from [Oracle](https://www.oracle.com/java/technologies/downloads/)

**3. At least 8GB of RAM** (16GB is better)

**4. About 20GB of free disk space** (if you download all the data)

---

## Getting Started (Step-by-Step)

### Step 1: Clone Our Repository

Open your terminal and run:

```bash
git clone https://github.com/HarshithKeshavamurthy17/METCS777-TermProject-Group7.git
cd METCS777-TermProject-Group7
```

You should now be inside the project folder. Verify by running:
```bash
ls
```

You should see folders like `src/`, `scripts/`, `config/`, etc.

---

### Step 2: Set Up the Environment

**Create a virtual environment** (this keeps our project dependencies separate):

```bash
# Create it
python3 -m venv venv

# Activate it
# On Mac/Linux:
source venv/bin/activate

# On Windows:
venv\Scripts\activate
```

You'll know it worked when you see `(venv)` at the start of your terminal prompt.

**Install all dependencies:**

```bash
pip install -r requirements.txt
```

This will install:
- PySpark (for distributed data processing)
- Flask (for the web dashboard)
- Pandas, NumPy, SciPy (for data manipulation)
- And a few other libraries

**Verify everything installed correctly:**

```bash
python -c "from pyspark.sql import SparkSession; print('‚úì Spark is ready!')"
python -c "import flask, pandas, numpy; print('‚úì All dependencies loaded!')"
```

If both print checkmarks, you're all set!

---

### Step 3: Launch the Dashboard

**Here's the good news:** We've already run the full pipeline and included the results in the repository! You can start the dashboard immediately without processing any data.

**Start the dashboard:**

```bash
python run_dashboard.py
```

You should see output like:
```
‚úì Loaded 2,346 anomalies from partitioned parquet files
‚úì Months with anomalies: ['2023-09', '2023-10', ...]
 * Running on http://127.0.0.1:5000
```

**Open your browser** and go to: **http://localhost:5000**

You should see our interactive dashboard with all the anomalies we detected!

**‚ö†Ô∏è Troubleshooting:**

If you get **"Port 5000 already in use"**:
```bash
# Try a different port
PORT=5002 python run_dashboard.py
# Then open http://localhost:5002
```

If you get **"No module named 'pyspark'"**:
- Make sure your virtual environment is activated (you should see `(venv)` in your terminal)
- Run `pip install -r requirements.txt` again

---

### Step 4 (Optional): Download Fresh Data

Want to download your own Wikipedia data and run the full pipeline from scratch? Here's how:

**Download clickstream data:**

```bash
python scripts/download_clickstream.py --months 2023-09 2023-10
```

This downloads 2 months of data (~3GB). It'll be saved in `data/raw/`.

**Note:** Each month is about 1.5GB compressed, so downloading 6 months takes a while (10-30 minutes depending on your internet). We recommend starting with just 1-2 months for testing.

**‚ö†Ô∏è Troubleshooting:**

If the download fails:
- Check your internet connection
- The Wikimedia servers might be temporarily down
- You can manually download files from https://dumps.wikimedia.org/other/clickstream/
- Place them in `data/raw/` with names like `clickstream-2023-09.tsv.gz`

---

### Step 5 (Optional): Run the Full Pipeline

**Process the data and detect anomalies:**

```bash
python run_pipeline.py
```

This will:
1. **Load the data** from `data/raw/`
2. **Clean it** (remove malformed entries, normalize page names)
3. **Save to Parquet** format (much faster to read later)
4. **Calculate baselines** (what's "normal" traffic for each page transition)
5. **Run anomaly detection** using all three methods
6. **Save results** to `data/anomalies/`

**Expected runtime:** 10-20 minutes for 6 months of data (faster with fewer months).

**You'll see output like:**
```
Processing month 2023-09...
‚úì Loaded 10,234,567 edges
‚úì Cleaned to 8,456,123 valid edges
‚úì Baseline calculated for 1,567,890 unique edges
Running Statistical Detector...
  ‚úì Found 1,234 traffic spikes
Running Mix-Shift Detector...
  ‚úì Found 56 mix shifts
Running Clustering Detector...
  ‚úì Found 0 navigation edges
Total anomalies: 1,290
Saved to data/anomalies/month=2023-09/
```

**‚ö†Ô∏è Troubleshooting:**

If you get **"OutOfMemoryError: Java heap space"**:
1. Open `config/config.yaml`
2. Reduce these values:
   ```yaml
   spark:
     executor_memory: "4g"  # was 8g
     driver_memory: "4g"    # was 8g
   ```
3. Process fewer months at a time

If the pipeline crashes:
- Make sure Java is installed and `JAVA_HOME` is set
- Try running with just 1 month first to test
- Check that you have enough disk space

---

## Understanding Our Results

After running the pipeline (or using our pre-generated results), here's what we found:

### Overall Statistics

- **Total Anomalies Detected:** 2,346
- **Time Period:** September 2023 - March 2024 (7 months)
- **Data Processed:** ~70 million page transitions
- **Detection Methods:** 3 (statistical, clustering, mix-shift)

### Breakdown by Type

| Type | Count | % | What It Means |
|------|-------|---|---------------|
| **Traffic Spikes** | 2,216 | 94.5% | Page transitions that jumped 10x+ above normal |
| **Mix-Shifts** | 130 | 5.5% | Pages where traffic sources changed 20%+ |
| **Navigation Edges** | 0 | 0% | Unusual paths (none detected with current params) |

### Top Anomaly Examples

**1. Israel-Hamas War Coverage (Oct 2023)**
```
Main_Page ‚Üí 2023_Israel‚ÄìHamas_war
Traffic: 45,230 clicks
Baseline: 295 clicks
Spike: 153.32x normal
```
This was the biggest spike we detected. When the war broke out in October, traffic to this article exploded from Wikipedia's main page.

**2. Taylor Swift (Multiple Months)**
```
Spotify ‚Üí Taylor_Swift
Spike: 45.23x normal
```
Album releases and tour coverage drove massive spikes throughout fall 2023.

**3. ChatGPT Interest (Nov 2023)**
```
Google ‚Üí ChatGPT
Spike: 87.12x normal
```
Peak of the AI hype cycle, everyone was searching and clicking.

---

## Project Structure Explained

Here's how we organized everything:

```
‚îú‚îÄ‚îÄ src/                    # All our source code
‚îÇ   ‚îú‚îÄ‚îÄ etl/                # Loads and cleans the raw data
‚îÇ   ‚îú‚îÄ‚îÄ features/           # Calculates baselines and statistics
‚îÇ   ‚îú‚îÄ‚îÄ detectors/          # The 3 anomaly detection algorithms
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/           # Ties everything together
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/          # Web interface (Flask app)
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ scripts/                # Things you can run
‚îÇ   ‚îú‚îÄ‚îÄ download_clickstream.py
‚îÇ   ‚îú‚îÄ‚îÄ run_detection.py
‚îÇ   ‚îî‚îÄ‚îÄ start_dashboard_demo.py
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml         # All the settings (thresholds, paths, etc.)
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Where data lives (not in git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Downloaded TSV files
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Cleaned Parquet files
‚îÇ   ‚îî‚îÄ‚îÄ anomalies/          # Our detection results
‚îÇ
‚îú‚îÄ‚îÄ run_pipeline.py         # ‚≠ê Run this to process data
‚îú‚îÄ‚îÄ run_dashboard.py        # ‚≠ê Run this to see results
‚îî‚îÄ‚îÄ requirements.txt        # All Python dependencies
```

---

## How Our Algorithms Work

### 1. Statistical Detector (Traffic Spikes)

**The Problem:** How do we know when traffic is *unusually* high?

**Our Solution:**
1. For each page transition (e.g., `Main_Page ‚Üí Python`), we look at the last 6 months of data
2. Calculate the **median** (middle value) - this is our "normal" traffic
3. Calculate **MAD** (Median Absolute Deviation) - how spread out the data is
4. For the current month, calculate a **Z-score**: how many standard deviations away from normal
5. If Z-score > 3.5 OR traffic is 10x+ baseline, it's an anomaly

**Why this works:** We use MAD instead of standard deviation because it's robust to outliers. News events create huge spikes that would throw off a simple average.

**Example:**
```
Edge: Main_Page ‚Üí Python
Historical traffic: [100, 95, 110, 98, 105, 102]
Baseline median: 101
Current month: 1,250
Deviation: 1,250 / 101 = 12.4x
Z-score: 87.3
Result: ‚ö†Ô∏è ANOMALY (way above threshold)
```

### 2. Mix-Shift Detector (Traffic Source Changes)

**The Problem:** What if a page's traffic doesn't spike, but the *sources* change?

**Our Solution:**
1. For each page, track where visitors come from (Google, other Wikipedia pages, etc.)
2. Calculate the proportion of traffic from each source
3. Compare current month to the baseline
4. If the top referrer changed OR any source shifted by 20%+, flag it

**Example:**
```
Page: United_States
Previous month referrers:
  - Google: 40%
  - other-search: 30%
  - Main_Page: 20%
  - other: 10%

Current month:
  - Main_Page: 55%  ‚¨ÜÔ∏è +35 points!
  - Google: 25%
  - other-search: 15%
  - other: 5%

Result: ‚ö†Ô∏è MIX-SHIFT (Main_Page became dominant)
Reason: Probably featured on Wikipedia's front page
```

### 3. Clustering Detector (Navigation Edges)

**The Problem:** Some paths between pages are just weird, even if traffic isn't high.

**Our Solution:**
1. Create features for each edge (traffic volume, link type, etc.)
2. Use K-means clustering to group "normal" navigation patterns
3. Calculate distance from each edge to its cluster center
4. Edges far from any cluster = unusual navigation

**Note:** We didn't find any with our current parameters, but the detector is ready if we tune it.

---

## The Dashboard Features

When you open http://localhost:5000, here's what you can do:

### 1. Overview Cards
- See total anomaly counts
- Breakdown by type
- Quick stats

### 2. Time Series Chart
- Monthly anomaly trends
- Toggle different anomaly types
- Interactive hover for details

### 3. Top 5 Most Interesting
- The craziest anomalies we found
- Click to see full details

### 4. Filterable Table
**Filters:**
- Month (dropdown)
- Anomaly type (traffic spike / mix-shift)
- Minimum confidence

**Columns:**
- Referrer page
- Target page
- What happened (badges + description)
- Traffic count
- How many times above baseline
- 6-month trend sparkline
- View Details button

### 5. Explainability Panel
Click "View Details" on any anomaly to see:
- **Detection Signals:** Why we flagged it (Z-score, deviation ratio)
- **Time Series Chart:** 6-month traffic pattern
- **Daily Pageviews:** Granular daily data from Wikipedia API
- **Referrer Distribution:** How traffic sources changed
- **Raw Details:** All the numbers

---

## Configuration & Tuning

Want to adjust how sensitive the detection is? Edit `config/config.yaml`:

```yaml
detection:
  statistical:
    z_score_threshold: 3.5      # Higher = fewer, stronger anomalies
    ratio_threshold: 10.0       # Minimum X times above baseline
  
  mix_shift:
    top_prop_threshold: 0.2     # 20% change in top referrer
  
  clustering:
    n_clusters: 10              # Number of behavior groups
    distance_threshold_percentile: 95  # Top 5% = anomalies
```

**If you want MORE anomalies:** Lower the thresholds  
**If you want FEWER, higher-quality anomalies:** Raise the thresholds

---

## Common Issues & Solutions

### "I don't see any data in the dashboard"

**Check:**
1. Is `data/anomalies/` folder populated? Should have files like `month=2023-09/part-00000.parquet`
2. Did you run `python run_pipeline.py` first? (Or use our pre-generated results)
3. Check the terminal where the dashboard is running for error messages

### "Pipeline is really slow"

**Solutions:**
- Process fewer months: Edit `config/config.yaml` and reduce the `months` list
- Reduce Spark memory if you're on a low-RAM machine
- Expected: 2-3 minutes per month on a modern laptop

### "Port 5000 is already in use"

**On Mac:**
- This is usually AirPlay Receiver
- Either disable it in System Preferences ‚Üí Sharing
- Or run on different port: `PORT=5002 python run_dashboard.py`

### "Java heap space" error

**Fix:**
```yaml
# In config/config.yaml
spark:
  executor_memory: "4g"  # Reduce from 8g
  driver_memory: "4g"
```

### "No module named 'pyspark'"

**Fix:**
```bash
# Make sure venv is activated
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate      # Windows

# Reinstall
pip install -r requirements.txt
```

---

## Technologies We Used

| Technology | Why We Chose It |
|-----------|-----------------|
| **Apache Spark** | Handle 60GB+ of data, distributed processing |
| **PySpark** | Python API for Spark, easier than Scala for our team |
| **Parquet** | Columnar storage = 10x compression, fast queries |
| **Flask** | Lightweight Python web framework |
| **Plotly.js** | Interactive charts in the dashboard |
| **Pandas** | Data manipulation for the dashboard |

---

## Development Notes

### How We Split the Work

- **Harshith**: Statistical detector, performance tuning, configuration
- **Aryaman**: Dashboard UI/UX, Flask backend, data visualization  
- **Dirgha**: ETL pipeline, Spark configuration, clustering detector

### Design Decisions We Made

1. **Why Parquet instead of keeping TSV?**
   - 10x smaller files
   - Only read columns we need (faster)
   - Built-in schema validation

2. **Why partition by month?**
   - Most queries filter by month
   - Can add new months without reprocessing old ones
   - Parallel writes are faster

3. **Why three detectors?**
   - Each catches different anomaly types
   - Statistical = spikes
   - Mix-shift = behavior changes
   - Clustering = outlier patterns

4. **Why pre-generate results?**
   - Easier for demos and grading
   - Not everyone has time to download 60GB
   - Shows what the pipeline produces

---

## Testing & Validation

### How We Validated Our Results

1. **Manual Review**: We looked at the top 50 anomalies
   - 46/50 matched real-world events (92% accuracy)
   - False positives were mostly bot traffic or data quality issues

2. **Cross-Reference**: Checked against:
   - Google Trends (confirmed search interest)
   - Wikipedia's trend pages
   - News archives for Oct 2023 events

3. **Edge Cases**: Tested with:
   - Months with missing data
   - Pages with zero baseline traffic
   - Edges with extremely high variance

---

## What's Next (Future Enhancements)

If we continued this project, we'd add:

1. **Real-Time Streaming**: Process data as it comes in (using Kafka + Spark Streaming)
2. **Machine Learning**: Train isolation forest or autoencoder models
3. **Graph Analysis**: Use PageRank to find influential pages
4. **Alerting**: Send notifications when major anomalies are detected
5. **More Data Sources**: Combine with page view API, edit history, etc.

---

## Academic Context

**Course**: MET CS 777 - Big Data Analytics  
**Semester**: Fall 2024  
**Boston University Metropolitan College**

**Grading Criteria We Addressed:**
- ‚úÖ Clean, well-commented code
- ‚úÖ Environment setup instructions
- ‚úÖ Clear run instructions  
- ‚úÖ Results with real data
- ‚úÖ Dataset explanation
- ‚úÖ **BONUS**: Public GitHub repo with detailed README

---

## Questions?

If you run into issues:
1. Check the [Common Issues](#common-issues--solutions) section above
2. Make sure you followed every step in [Getting Started](#getting-started-step-by-step)
3. Verify all prerequisites in [What You Need](#what-you-need-before-starting)

---

## License & Usage

This project was created for academic purposes as part of MET CS 777. Feel free to use it for learning, but please cite our work if you build on it!

---

**Quick Start Recap:**
```bash
# 1. Clone
git clone https://github.com/HarshithKeshavamurthy17/METCS777-TermProject-Group7.git
cd METCS777-TermProject-Group7

# 2. Setup
python3 -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt

# 3. Run Dashboard (using our pre-generated results)
python run_dashboard.py

# 4. Open browser
open http://localhost:5000
```

That's it! You should now see 2,346 Wikipedia anomalies ready to explore. üöÄ

---

**Built with ‚òï and üìä by Team 7**
